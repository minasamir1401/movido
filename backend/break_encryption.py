"""
Ø£Ø¯Ø§Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„ÙƒØ³Ø± ØªØ´ÙÙŠØ± Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
"""
import asyncio
import base64
import re
import json
from curl_cffi.requests import AsyncSession
from urllib.parse import unquote, urlparse

async def break_server_encryption():
    """ÙƒØ³Ø± ØªØ´ÙÙŠØ± Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©"""
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    with open("extracted_servers.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    
    servers = data['servers']
    
    print("=" * 80)
    print("ğŸ”“ ÙƒØ³Ø± ØªØ´ÙÙŠØ± Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª")
    print("=" * 80)
    print(f"\nğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª: {len(servers)}")
    
    session = AsyncSession(impersonate="chrome124", timeout=15, verify=False)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "ar,en-US;q=0.9",
    }
    
    direct_links = []
    
    for i, server in enumerate(servers, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ¬ Ø§Ù„Ø³ÙŠØ±ÙØ± {i}/{len(servers)}: {server['name']}")
        print(f"ğŸ”— URL: {server['url'][:80]}...")
        print(f"{'='*80}")
        
        url = server['url']
        server_type = None
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³ÙŠØ±ÙØ±
        if 'okprime' in url or 'ok.ru' in url:
            server_type = 'okprime'
        elif 'mixdrop' in url or 'mxdrop' in url:
            server_type = 'mixdrop'
        elif 'dood' in url:
            server_type = 'doodstream'
        elif 'voe' in url:
            server_type = 'voe'
        elif 'vidmoly' in url:
            server_type = 'vidmoly'
        elif 'upstream' in url:
            server_type = 'upstream'
        elif 'short.icu' in url:
            server_type = 'shortlink'
        elif 'vk.com' in url:
            server_type = 'vk'
        else:
            server_type = 'generic'
        
        print(f"ğŸ“Œ Ø§Ù„Ù†ÙˆØ¹: {server_type.upper()}")
        
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø©
            resp = await session.get(url, headers=headers, allow_redirects=True)
            html = resp.text
            final_url = str(resp.url)
            
            print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø© (Ø§Ù„Ø­Ø¬Ù…: {len(html)} Ø­Ø±Ù)")
            if final_url != url:
                print(f"ğŸ”„ ØªÙ… Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø¥Ù„Ù‰: {final_url[:80]}...")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
            extracted = []
            
            # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· M3U8
            m3u8_patterns = [
                r'["\']([^"\']*\.m3u8[^"\']*)["\']',
                r'file:\s*["\']([^"\']+\.m3u8[^"\']*)["\']',
                r'source:\s*["\']([^"\']+\.m3u8[^"\']*)["\']',
                r'src:\s*["\']([^"\']+\.m3u8[^"\']*)["\']',
            ]
            
            for pattern in m3u8_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE)
                for match in matches:
                    if 'http' in match:
                        extracted.append({"type": "m3u8", "url": match})
            
            # 2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· MP4
            mp4_patterns = [
                r'["\']([^"\']*\.mp4[^"\']*)["\']',
                r'file:\s*["\']([^"\']+\.mp4[^"\']*)["\']',
                r'source:\s*["\']([^"\']+\.mp4[^"\']*)["\']',
            ]
            
            for pattern in mp4_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE)
                for match in matches:
                    if 'http' in match and not any(x in match for x in ['.js', '.css']):
                        extracted.append({"type": "mp4", "url": match})
            
            # 3. ÙÙƒ ØªØ´ÙÙŠØ± Base64 Ø§Ù„Ù…Ø®ÙÙŠ
            b64_patterns = [
                r'atob\(["\']([A-Za-z0-9+/=]+)["\']\)',
                r'base64[,\s]*["\']([A-Za-z0-9+/=]{20,})["\']\)',
            ]
            
            for pattern in b64_patterns:
                matches = re.findall(pattern, html)
                for match in matches:
                    try:
                        decoded = base64.b64decode(match).decode('utf-8', errors='ignore')
                        if 'http' in decoded and ('.m3u8' in decoded or '.mp4' in decoded):
                            extracted.append({"type": "base64_decoded", "url": decoded})
                    except:
                        pass
            
            # 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† JavaScript Ø§Ù„Ù…Ø¹Ù‚Ø¯
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† eval(function(p,a,c,k,e,d))
            if 'eval(function(p,a,c,k,e' in html:
                print("   ğŸ” ÙˆØ¬Ø¯Ù†Ø§ JavaScript Ù…Ø´ÙØ± (packed)...")
                # Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±
                packed_pattern = r"eval\(function\(p,a,c,k,e,.*?\)\)"
                packed = re.findall(packed_pattern, html, re.DOTALL)
                if packed:
                    print(f"   ğŸ“¦ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(packed)} ÙƒÙˆØ¯ Ù…Ø´ÙØ±")
            
            # 5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ø§Øµ Ø¨ÙƒÙ„ Ù†ÙˆØ¹ Ø³ÙŠØ±ÙØ±
            if server_type == 'okprime':
                # OkPrime ØºØ§Ù„Ø¨Ø§Ù‹ ÙŠØ³ØªØ®Ø¯Ù… sources array
                sources_pattern = r'sources:\s*\[(.*?)\]'
                sources_match = re.search(sources_pattern, html, re.DOTALL)
                if sources_match:
                    sources_text = sources_match.group(1)
                    urls = re.findall(r'["\']([^"\']+\.(?:m3u8|mp4)[^"\']*)["\']', sources_text)
                    for url_found in urls:
                        extracted.append({"type": "okprime_source", "url": url_found})
            
            elif server_type == 'voe':
                # VOE ÙŠØ³ØªØ®Ø¯Ù… 'hls' variable
                hls_pattern = r'["\']hls["\']\s*:\s*["\']([^"\']+)["\']'
                hls_match = re.search(hls_pattern, html)
                if hls_match:
                    extracted.append({"type": "voe_hls", "url": hls_match.group(1)})
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
            unique_extracted = []
            seen_urls = set()
            for item in extracted:
                url_clean = item['url'].split('?')[0]  # Ø¥Ø²Ø§Ù„Ø© query params Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                if url_clean not in seen_urls:
                    seen_urls.add(url_clean)
                    unique_extracted.append(item)
            
            if unique_extracted:
                print(f"\nâœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(unique_extracted)} Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±:")
                for j, link in enumerate(unique_extracted, 1):
                    print(f"   {j}. [{link['type']}] {link['url'][:80]}...")
                    direct_links.append({
                        "server": server['name'],
                        "server_url": url,
                        "type": link['type'],
                        "direct_url": link['url'],
                        "source": server['source']
                    })
            else:
                print("   âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© (Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ JavaScript execution)")
            
            # ØªØ£Ø®ÙŠØ± ØµØºÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø±
            await asyncio.sleep(0.5)
            
        except Exception as e:
            print(f"   âŒ Ø®Ø·Ø£: {e}")
    
    await session.close()
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\n" + "=" * 80)
    print("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©")
    print("=" * 80)
    
    result = {
        "total_servers": len(servers),
        "direct_links_found": len(direct_links),
        "links": direct_links
    }
    
    with open("direct_links.json", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(direct_links)} Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø± Ù…Ù† {len(servers)} Ø³ÙŠØ±ÙØ±")
    print(f"ğŸ“ ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙÙŠ: direct_links.json")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    print("\n" + "=" * 80)
    print("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
    print("=" * 80)
    
    types_count = {}
    for link in direct_links:
        link_type = link['type']
        types_count[link_type] = types_count.get(link_type, 0) + 1
    
    print(f"\nğŸ“ˆ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©:")
    for ltype, count in sorted(types_count.items(), key=lambda x: x[1], reverse=True):
        print(f"   {ltype}: {count} Ø±Ø§Ø¨Ø·")
    
    # Ø£ÙØ¶Ù„ Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª
    print(f"\nğŸ† Ø£ÙØ¶Ù„ Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª (Ø§Ù„ØªÙŠ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ù…Ù†Ù‡Ø§):")
    server_success = {}
    for link in direct_links:
        server_name = link['server']
        server_success[server_name] = server_success.get(server_name, 0) + 1
    
    for server, count in sorted(server_success.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"   âœ… {server}: {count} Ø±Ø§Ø¨Ø·")
    
    print("\n" + "=" * 80)
    print("âœ… Ø§ÙƒØªÙ…Ù„ ÙƒØ³Ø± Ø§Ù„ØªØ´ÙÙŠØ±!")
    print("=" * 80)

if __name__ == "__main__":
    asyncio.run(break_server_encryption())
