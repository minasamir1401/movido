
import asyncio
import logging
import sys
import os

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù€ python path Ù„Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from scraper.engine import scraper

async def debug_episode():
    query = "Ù…Ø³Ù„Ø³Ù„ Ø§Ù„Ø­Ù„Ø§Ù†Ø¬ÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© 5"
    print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query}...")
    
    results = await scraper.search(query)
    if not results:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø«.")
        return

    # Ø¬Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø© (ØºØ§Ù„Ø¨Ø§Ù‹ Ù‡ÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©)
    target = results[0]
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰: {target['title']}")
    print(f"ğŸ”— Ø§Ù„Ø±Ø§Ø¨Ø·: {target['url']}")
    
    print("\nğŸ“¦ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª...")
    details = await scraper.fetch_details(target['id'])
    
    if details.get('servers'):
        print(f"ğŸ‰ Ù†Ø¬Ø­ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬! ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(details['servers'])} Ø³ÙŠØ±ÙØ±:")
        for s in details['servers']:
            print(f" - {s['name']}: {s['url']}")
    else:
        print("âŒ ÙØ´Ù„! Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³ÙŠØ±ÙØ±Ø§Øª.")
        
    if details.get('download_links'):
        print(f"\nğŸ“¥ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ ({len(details['download_links'])}):")
        for dl in details['download_links']:
            print(f" - {dl['quality']}: {dl['url']}")
    else:
        print("\nâŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø· ØªØ­Ù…ÙŠÙ„.")

if __name__ == "__main__":
    asyncio.run(debug_episode())
