
import asyncio
import logging
import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from scraper.engine import scraper

async def debug_servers():
    query = "Ù…Ø³Ù„Ø³Ù„ Ø¨Ø·Ù„ Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù„Ù‚Ø© 10"
    print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query}...")
    
    results = await scraper.search(query)
    if not results:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬.")
        return

    target = results[0]
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰: {target['title']}")
    
    print("\nğŸ“¦ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØ§ÙØ© Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª...")
    details = await scraper.fetch_details(target['id'])
    
    if details.get('servers'):
        print(f"ğŸ‰ Ù†Ø¬Ø­ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬! ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(details['servers'])} Ø³ÙŠØ±ÙØ±:")
        for idx, s in enumerate(details['servers'], 1):
            print(f" {idx}. {s['name']}: {s['url']}")
    else:
        print("âŒ ÙØ´Ù„! Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø³ÙŠØ±ÙØ±Ø§Øª.")

if __name__ == "__main__":
    asyncio.run(debug_servers())
